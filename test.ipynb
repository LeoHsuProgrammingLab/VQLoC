{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vision/hwjiang/anaconda3/envs/vq2d/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3, -2, -1,  0,  1,  2,  3],\n",
       "        [-2, -1,  0,  1,  2,  3,  4],\n",
       "        [-1,  0,  1,  2,  3,  4,  5],\n",
       "        [ 0,  1,  2,  3,  4,  5,  6],\n",
       "        [ 1,  2,  3,  4,  5,  6,  7],\n",
       "        [ 2,  3,  4,  5,  6,  7,  8],\n",
       "        [ 3,  4,  5,  6,  7,  8,  9],\n",
       "        [ 4,  5,  6,  7,  8,  9, 10],\n",
       "        [ 5,  6,  7,  8,  9, 10, 11],\n",
       "        [ 6,  7,  8,  9, 10, 11, 12]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(-3, 3 + 1) + torch.arange(10)[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "You're right, the padded zeros can influence the results. I'll update the implementation to include a mask for the transformer_decoder_layer. Here's the revised implementation:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class TemporalLocalWindowAttentionGather(nn.Module):\n",
    "    def __init__(self, d_model, nhead, window_size=3):\n",
    "        super(TemporalLocalWindowAttentionGather, self).__init__()\n",
    "        self.window_size = window_size\n",
    "        self.transformer_decoder_layer = nn.TransformerDecoderLayer(d_model, nhead)\n",
    "\n",
    "    def gather_key_value(self, x, window_size):\n",
    "        b, t, n, c = x.shape\n",
    "\n",
    "        # Pad the input tensor along the time dimension\n",
    "        pad_size = window_size // 2\n",
    "        x_padded = torch.cat([x.new_zeros(b, pad_size, n, c), x, x.new_zeros(b, pad_size, n, c)], dim=1)    # [b,t+2p,n,c]\n",
    "\n",
    "        # Create indices for gathering key and value tensors\n",
    "        indices = torch.arange(-pad_size, pad_size + 1, dtype=torch.long, device=x.device) + torch.arange(t)[:, None]   # [2p+1,t]\n",
    "        indices = indices[None, :, None, None].expand(b, -1, n, c)\n",
    "\n",
    "        key_value = torch.gather(x_padded, 1, indices)\n",
    "        key_value = key_value.view(b, t, window_size * n, c).transpose(2, 3)\n",
    "\n",
    "        return key_value\n",
    "\n",
    "    def generate_mask(self, b, t, n, c, window_size):\n",
    "        pad_size = window_size // 2\n",
    "        mask = torch.zeros(b, t, window_size * n, dtype=torch.bool, device=x.device)\n",
    "        mask[:, :, pad_size * n:(pad_size + t) * n] = True\n",
    "        return mask\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, t, n, c = x.shape\n",
    "        query = x.view(b, t * n, c)\n",
    "\n",
    "        key_value = self.gather_key_value(x, self.window_size)\n",
    "        mask = self.generate_mask(b, t, n, c, self.window_size)\n",
    "        output = self.transformer_decoder_layer(query, key_value, key_padding_mask=mask)\n",
    "        output = output.view(b, t, n, c)\n",
    "\n",
    "        return output\n",
    "\n",
    "# Example usage:\n",
    "d_model = 64\n",
    "nhead = 8\n",
    "batch_size = 16\n",
    "num_frames = 10\n",
    "num_tokens = 50\n",
    "\n",
    "video_features = torch.randn(batch_size, num_frames, num_tokens, d_model)\n",
    "temporal_local_window_attention_gather = TemporalLocalWindowAttentionGather(d_model, nhead)\n",
    "output = temporal_local_window_attention_gather(video_features)\n",
    "\n",
    "print(\"Output shape: \", output.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vq2d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
